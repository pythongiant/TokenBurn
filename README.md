
---

## ðŸ“š References & Inspiration

This library was inspired by recent research on log-probabilities and Bayesian interpretations of LLMs:

* **â€œLLMs are Bayesian, in Expectation, not in Realizationâ€**
  [arXiv:2507.11768](https://arxiv.org/pdf/2507.11768)

These ideas motivated the **hallucination risk scoring** and **optimal CoT length scaling** methods implemented in TokenBurn.

---
# ðŸ”¥ TokenBurn

**TokenBurn** is a lightweight Python library for analyzing the confidence of Large Language Models (LLMs).
It helps you detect **hallucinations**, compute **perplexity**, and find the **optimal chain-of-thought (CoT) length** using scaling laws.

It works with any Hugging Face / OpenAI-compatible inference server that supports logprobs.

---

## ðŸš€ Features

* âœ… Extract **logprobs** from LLM outputs
* âœ… Compute **perplexity** (model confidence)
* âœ… Detect **hallucination risk** using entropy + variance
* âœ… Estimate **optimal CoT length** with scaling law
* âœ… Compatible with Hugging Face Inference API / OpenAI-like endpoints

---

## ðŸ“¦ Installation

Clone the repo and install requirements:

```bash
git clone https://github.com/yourname/tokenburn.git
cd tokenburn
pip install -r requirements.txt
```

Or install directly from local path:

```bash
pip install -e .
```

---

## âš¡ Quickstart
### Code:
```python
from tokenburn.tokenburn import TokenBurn

# Initialize TokenBurn with your model + endpoint
tb = TokenBurn(
    url="https://router.huggingface.co/v1/chat/completions",
    model="openai/gpt-oss-120b:cerebras",
    api_key="hf_xxxxx"   # Replace with your HF API key
)

# Example 1: A question that may cause hallucination
logprobs = tb.get_logprobs(messages=[
    {"role": "user", "content": "Who won the Nobel Prize in Physics in 2029?"}
], max_tokens=50, top_logprobs=5)

print("Perplexity:", tb.perplexity(logprobs))
print("Hallucination Risk:", tb.hallucination_risk(logprobs))
print("Optimal CoT Length:", tb.find_optimal_cot_length(n=len(logprobs), epsilon=0.9))

# Example 2: A well-known fact
logprobs = tb.get_logprobs(messages=[
    {"role": "user", "content": "What is the capital of France?"}
], max_tokens=50, top_logprobs=5)

print("Perplexity:", tb.perplexity(logprobs))
print("Hallucination Risk:", tb.hallucination_risk(logprobs))
print("Optimal CoT Length:", tb.find_optimal_cot_length(n=len(logprobs), epsilon=0.9))
```
### Output:
```text
Perplexity: 1.7654718506453648
Hallucination Risk: {'risk': 'HIGH', 'avg_entropy': 0.16010855028274482, 'variance': 1.310231613318954}
Optimal CoT Length: 1
Perplexity: 1.2230227331760852
Hallucination Risk: {'risk': 'LOW', 'avg_entropy': 0.096105875932574, 'variance': 0.23889273251666965}
Optimal CoT Length: 0
```
---

## ðŸ“Š Metrics Explained

### ðŸ”¹ Perplexity

* Measures how confident the model is in its predictions.
* **Low perplexity (â‰ˆ1â€“20)** â†’ high confidence, usually factual.
* **High perplexity (>50)** â†’ uncertainty, higher chance of hallucination.

### ðŸ”¹ Hallucination Risk

* Based on:

  * **Entropy**: how spread out the modelâ€™s probability distribution is.
  * **Variance**: how much token confidence fluctuates.
* Returns **LOW / MEDIUM / HIGH**.

### ðŸ”¹ Optimal CoT Length

* Uses a scaling law:

  $$
  k^* â‰ˆ \sqrt{\frac{Î±n}{H_{cot}(B_0 - B_{opt})}} \cdot \log_2\left(\frac{1}{\epsilon}\right)
  $$
* Helps decide how many reasoning steps the model should generate before stopping.

---

## ðŸ“‚ Project Structure

```
tokenburn/
â”‚â”€â”€ tokenburn.py         # Main TokenBurn class
â”‚â”€â”€ utils/
â”‚    â””â”€â”€ metrics.py      # Perplexity, hallucination risk, CoT length functions
```

---

## âœ… Example Use Cases

* Detect when your LLM is **guessing vs. confident**.
* Auto-stop generation when hallucination risk is **HIGH**.
* Compare models by **perplexity stability**.
* Tune reasoning length dynamically with **optimal CoT scaling**.

---

## ðŸ›  Roadmap

* [ ] Add visualization for perplexity & entropy
* [ ] Support for streaming logprobs
* [ ] Prebuilt benchmarking suite with hallucination prompts

---

## ðŸ“œ License

MIT License â€“ feel free to use and modify.

